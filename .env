# .env
# Configuration for the TEI deployment

# --- Model Configuration ---
MODEL_ID=Alibaba-NLP/gte-modernbert-base # MAKE SURE THIS IS COMPATIBLE
EMBEDDING_DIMENSION=768        # !!! SET THIS TO YOUR MODEL'S OUTPUT DIMENSION !!!
AUTO_TRUNCATE=True
# REVISION=main

# --- Deployment Configuration ---
NUM_REPLICAS=2 # Number of TEI replicas
HOST_PORT=8080 # Port for the CACHE PROXY service

# --- TEI Container Configuration ---
TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:latest # Or specific version
MAX_BATCH_TOKENS=16384
# DTYPE=float16
# HUGGING_FACE_HUB_TOKEN=your_hf_token_here

# --- Qdrant Cache Configuration ---
QDRANT_COLLECTION=text_embedding_cache
QDRANT_HOST=qdrant # Service name in docker-compose
QDRANT_PORT=6333   # Default Qdrant gRPC port

# --- Cache Proxy Configuration ---
# URL for the Nginx load balancer *inside* the docker network
NGINX_UPSTREAM_URL=http://nginx:80
CACHE_HASH_FUNCTION=sha256 # Or md5 (faster but higher collision risk)